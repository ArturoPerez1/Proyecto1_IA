{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPIbLMu85_9b"
      },
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "\"\"\"\n",
        "# Proyecto: Predictor de Calidad de Vino 🍷\n",
        "**Fase de Google Colab: Exploración, Preprocesamiento y Entrenamiento del Modelo**\n",
        "\n",
        "**Objetivo**: Cargar y explorar el dataset, preprocesar los datos (manejo de ausentes y escalado),\n",
        "entrenar un modelo de Machine Learning para predecir la calidad del vino (regresión),\n",
        "y guardar el modelo junto con los preprocesadores para su uso en la aplicación GUI.\n",
        "\"\"\"\n",
        "\n",
        "# %% [markdown]\n",
        "\"\"\"\n",
        "## Paso 1: Configuración Inicial y Carga de Librerías\n",
        "\"\"\"\n",
        "\n",
        "# %%\n",
        "# Librerías esenciales para manipulación de datos y visualización\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Scikit-learn para preprocesamiento y modelado\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Para guardar y cargar objetos de Python (modelos, transformadores)\n",
        "import joblib\n",
        "\n",
        "# %% [markdown]\n",
        "\"\"\"\n",
        "## Paso 2: Carga y Exploración de Datos (EDA)\n",
        "\"\"\"\n",
        "\n",
        "# %%\n",
        "# 2.1 Cargar el Wine Quality Dataset\n",
        "file_path_drive = '/content/winequality-red.csv' \n",
        "df = None \n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(file_path_drive, sep=';')\n",
        "    print(f\"Dataset cargado exitosamente desde '{file_path_drive}' con separador ';'.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: El archivo no se encontró en la ruta '{file_path_drive}'.\")\n",
        "    print(\"Por favor, asegúrate de que el archivo CSV esté en tu Google Drive y la ruta sea correcta.\")\n",
        "    print(\"Creando un DataFrame de ejemplo para continuar la ejecución.\")\n",
        "    # Crear un DataFrame de ejemplo para que el resto del código funcione\n",
        "    data = {\n",
        "        'fixed acidity': np.random.rand(100) * 5 + 5,\n",
        "        'volatile acidity': np.random.rand(100) * 0.5 + 0.2,\n",
        "        'citric acid': np.random.rand(100) * 0.5,\n",
        "        'residual sugar': np.random.rand(100) * 5 + 1,\n",
        "        'chlorides': np.random.rand(100) * 0.1 + 0.03,\n",
        "        'free sulfur dioxide': np.random.rand(100) * 50 + 10,\n",
        "        'total sulfur dioxide': np.random.rand(100) * 100 + 50,\n",
        "        'density': np.random.rand(100) * 0.005 + 0.995,\n",
        "        'pH': np.random.rand(100) * 0.5 + 3.0,\n",
        "        'sulphates': np.random.rand(100) * 0.5 + 0.5,\n",
        "        'alcohol': np.random.rand(100) * 5 + 9,\n",
        "        'quality': np.random.randint(3, 9, 100)\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    print(\"¡Advertencia! Se ha cargado un DataFrame de ejemplo. Para el proyecto real, debes cargar el dataset de vino.\")\n",
        "except pd.errors.ParserError:\n",
        "    print(f\"Error de parsing al cargar '{file_path_drive}'. Probablemente el separador no es ';'.\")\n",
        "    print(\"Intentando cargar con ',' como separador.\")\n",
        "    try:\n",
        "        df = pd.read_csv(file_path_drive, sep=',')\n",
        "        print(f\"Dataset cargado exitosamente desde '{file_path_drive}' con separador ','.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al cargar el dataset con ambos separadores. Por favor, verifica la ruta y el archivo: {e}\")\n",
        "        print(\"Creando un DataFrame de ejemplo como último recurso.\")\n",
        "        data = { # DataFrame de ejemplo (mismo que antes)\n",
        "            'fixed acidity': np.random.rand(100) * 5 + 5, 'volatile acidity': np.random.rand(100) * 0.5 + 0.2,\n",
        "            'citric acid': np.random.rand(100) * 0.5, 'residual sugar': np.random.rand(100) * 5 + 1,\n",
        "            'chlorides': np.random.rand(100) * 0.1 + 0.03, 'free sulfur dioxide': np.random.rand(100) * 50 + 10,\n",
        "            'total sulfur dioxide': np.random.rand(100) * 100 + 50, 'density': np.random.rand(100) * 0.005 + 0.995,\n",
        "            'pH': np.random.rand(100) * 0.5 + 3.0, 'sulphates': np.random.rand(100) * 0.5 + 0.5,\n",
        "            'alcohol': np.random.rand(100) * 5 + 9, 'quality': np.random.randint(3, 9, 100)\n",
        "        }\n",
        "        df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "# 2.2 Análisis exploratorio inicial del dataset\n",
        "print(\"\\n--- Vista Previa del Dataset (Primeras 5 filas) ---\")\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\n--- Columnas del DataFrame después de la carga ---\")\n",
        "print(df.columns)\n",
        "\n",
        "print(\"\\n--- Información General del Dataset ---\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\n--- Estadísticas Descriptivas de las Columnas Numéricas ---\")\n",
        "print(df.describe())\n",
        "\n",
        "print(\"\\n--- Verificación de Valores Ausentes en el Dataset Original ---\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "if df.isnull().sum().sum() == 0:\n",
        "    print(\"\\nConfirmación: El dataset original no contiene valores ausentes.\")\n",
        "else:\n",
        "    print(\"\\nAdvertencia: El dataset original contiene valores ausentes. Esto podría requerir preprocesamiento adicional si no es intencionado.\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Distribución de la Variable Objetivo 'quality' ---\")\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x='quality', data=df)\n",
        "plt.title('Distribución de la Calidad del Vino')\n",
        "plt.xlabel('Calidad')\n",
        "plt.ylabel('Número de Vinos')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "# %% [markdown]\n",
        "\"\"\"\n",
        "## Paso 3: Preprocesamiento de Datos para el Modelo\n",
        "\"\"\"\n",
        "\n",
        "# %%\n",
        "# 3.1 Separar características (X) y la variable objetivo (y)\n",
        "X = df.drop('quality', axis=1) # Todas las columnas excepto 'quality' son características de entrada\n",
        "y = df['quality'] # 'quality' es la variable que queremos predecir\n",
        "\n",
        "print(f\"\\nDimensiones de X (características): {X.shape}\")\n",
        "print(f\"Dimensiones de y (variable objetivo): {y.shape}\")\n",
        "\n",
        "# 3.2 Dividir el dataset en conjuntos de entrenamiento y prueba\n",
        "# Usaremos un 80% para entrenamiento y un 20% para prueba.\n",
        "# random_state asegura que la división sea reproducible.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"\\nDimensiones del conjunto de entrenamiento X_train: {X_train.shape}\")\n",
        "print(f\"Dimensiones del conjunto de prueba X_test: {X_test.shape}\")\n",
        "print(f\"Dimensiones del objetivo de entrenamiento y_train: {y_train.shape}\")\n",
        "print(f\"Dimensiones del objetivo de prueba y_test: {y_test.shape}\")\n",
        "\n",
        "# 3.3 Imputación de Valores Ausentes (para la inferencia futura en la GUI)\n",
        "# Aunque el dataset de entrenamiento no tiene ausentes, necesitamos un imputer entrenado\n",
        "# para manejar los valores ausentes que el usuario podría no ingresar en la GUI.\n",
        "# Usaremos KNNImputer para una imputación más robusta.\n",
        "# n_neighbors: número de vecinos a considerar para la imputación. 5 es un valor común.\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "\n",
        "# Ajustar el imputer SOLO al conjunto de entrenamiento.\n",
        "# Esto asegura que la imputación se base solo en los datos \"conocidos\" por el modelo.\n",
        "imputer.fit(X_train)\n",
        "\n",
        "# Transformar los conjuntos de entrenamiento y prueba usando el imputer (aunque no tengan ausentes,\n",
        "# esto es para completar la secuencia si el imputer se usara en un pipeline).\n",
        "# Para este flujo, es más importante guardar el imputer ajustado.\n",
        "X_train_imputed = imputer.transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "\n",
        "# Guardar el imputer entrenado. Este archivo se cargará en la aplicación GUI.\n",
        "imputer_filename = '/content/wine_quality_imputer.joblib'\n",
        "joblib.dump(imputer, imputer_filename)\n",
        "print(f\"\\nImputer (KNNImputer) guardado en Google Drive como '{imputer_filename}'.\")\n",
        "\n",
        "\n",
        "# 3.4 Escalado de Características\n",
        "# Creamos un escalador para normalizar los datos (media 0, varianza 1).\n",
        "# Esto es una buena práctica para muchos modelos de ML, aunque Random Forest es menos sensible.\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Ajustamos el escalador SOLO en el conjunto de entrenamiento y luego lo transformamos.\n",
        "# Es fundamental para evitar la fuga de datos (data leakage) del conjunto de prueba.\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed) # Aplicamos escalado sobre datos ya imputados\n",
        "X_test_scaled = scaler.transform(X_test_imputed) # Transformamos test con el scaler ajustado en train\n",
        "\n",
        "print(\"\\nCaracterísticas escaladas usando StandardScaler.\")\n",
        "print(f\"Primeras 5 filas de X_train_scaled (escalado):\\n{X_train_scaled[:5]}\")\n",
        "\n",
        "# Guardar el scaler entrenado. Este archivo también se cargará en la aplicación GUI.\n",
        "scaler_filename = '/content/wine_quality_scaler.joblib'\n",
        "joblib.dump(scaler, scaler_filename)\n",
        "print(f\"\\nScaler (StandardScaler) guardado en Google Drive como '{scaler_filename}'.\")\n",
        "\n",
        "# %% [markdown]\n",
        "\"\"\"\n",
        "## Paso 4: Desarrollo del Modelo de Machine Learning\n",
        "\"\"\"\n",
        "\n",
        "# %%\n",
        "print(\"\\n--- Iniciando el Desarrollo del Modelo de Machine Learning ---\")\n",
        "\n",
        "# 4.1 Elección y Configuración del Algoritmo de ML\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "# n_estimators: número de árboles. Más árboles suelen dar mejor rendimiento.\n",
        "# random_state: para reproducibilidad.\n",
        "# n_jobs=-1: usa todos los cores del CPU disponibles para acelerar el entrenamiento.\n",
        "print(\"\\nModelo seleccionado: Random Forest Regressor\")\n",
        "print(f\"Parámetros del modelo: {model.get_params()}\")\n",
        "\n",
        "# 4.2 Entrenar el Modelo\n",
        "# Entrenamos el modelo con los datos de entrenamiento ya preprocesados (imputados y escalados).\n",
        "print(\"\\nEntrenando el modelo...\")\n",
        "model.fit(X_train_scaled, y_train)\n",
        "print(\"¡Modelo entrenado exitosamente!\")\n",
        "\n",
        "# 4.3 Evaluación del Rendimiento del Modelo\n",
        "# Realizamos predicciones sobre el conjunto de prueba escalado.\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculamos métricas de evaluación para modelos de regresión.\n",
        "# Mean Squared Error (MSE): Mide el error promedio de las predicciones al cuadrado.\n",
        "# Un valor más bajo indica que las predicciones están más cerca de los valores reales.\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"\\nError Cuadrático Medio (MSE) en el conjunto de prueba: {mse:.4f}\")\n",
        "\n",
        "# Root Mean Squared Error (RMSE): Es la raíz cuadrada del MSE, lo que lo hace más interpretable\n",
        "# al estar en la misma unidad que la variable objetivo (calidad).\n",
        "rmse = np.sqrt(mse)\n",
        "print(f\"Raíz del Error Cuadrático Medio (RMSE) en el conjunto de prueba: {rmse:.4f}\")\n",
        "\n",
        "\n",
        "# R-squared (R2 Score): Mide la proporción de la varianza en la variable objetivo que es\n",
        "# predecible a partir de las características de entrada.\n",
        "# Un valor más cercano a 1 indica un mejor ajuste del modelo.\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"Coeficiente de Determinación (R2 Score) en el conjunto de prueba: {r2:.4f}\")\n",
        "\n",
        "# Visualización de las predicciones vs. valores reales\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.6)\n",
        "# Línea de referencia ideal: donde la predicción es igual al valor real\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "plt.title('Predicciones del Modelo vs. Valores Reales de Calidad')\n",
        "plt.xlabel('Calidad Real')\n",
        "plt.ylabel('Calidad Predicha')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 4.4 Guardar el Modelo Entrenado\n",
        "# Es esencial guardar el modelo entrenado para poder cargarlo y usarlo en la aplicación GUI\n",
        "# sin tener que reentrenarlo cada vez.\n",
        "# Usamos joblib porque es eficiente para guardar y cargar objetos de scikit-learn.\n",
        "model_filename = '/content/wine_quality_model.joblib'\n",
        "joblib.dump(model, model_filename)\n",
        "print(f\"\\nModelo entrenado guardado exitosamente en: {model_filename}\")\n",
        "\n",
        "print(\"\\n--- Desarrollo del Modelo de Machine Learning Completado ---\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
